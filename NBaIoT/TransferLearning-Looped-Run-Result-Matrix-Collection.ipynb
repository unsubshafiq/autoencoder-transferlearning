{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Looped-Run-WithOut-FS-Result-Collection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNz/UKELpzP5nCSohPU+VkE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTYln-9upeeQ","executionInfo":{"status":"ok","timestamp":1644769788046,"user_tz":-300,"elapsed":25838,"user":{"displayName":"Unsub Shafiq","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07945986632191365791"}},"outputId":"2498f99e-d792-4b6e-a96b-a5b5b87c051c"},"source":["# Importing general libraries\n","from glob import iglob\n","import math\n","import time\n","import  sys\n","import difflib\n","import io\n","from contextlib import redirect_stdout\n","import os\n","\n","# Import ML related libraries\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras.utils import plot_model\n","from keras.models import load_model\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense\n","from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n","from keras import backend as K\n","from keras.initializers import glorot_uniform\n","#from keras.optimizers import SGD\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score, confusion_matrix, plot_confusion_matrix\n","#import lime\n","#import lime.lime_tabular\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","# Checking the version of the of installed / available libraries\n","# print(\"Python: \" + str(sys.version_info.major) + \".\" + str(sys.version_info.minor))\n","# print(\"Tensorflow: \" + str(tf.__version__))\n","# print(\"Keras: \" + str(keras.__version__))\n","# print(\"ScikitLearn: \" + str(sklearn.__version__))\n","# print(\"Pandas: \" + str(pd.__version__))\n","# print(\"NumPy: \" + str(np.__version__))\n","\n","# Fetching the data from Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"98WR2L9dpwt6"},"source":["# MetaData\n","Device_Listing = ['SimpleHome_XCS7_1003_WHT_Security_Camera',  \n","                 'SimpleHome_XCS7_1002_WHT_Security_Camera',\n","                 'Provision_PT_838_Security_Camera',\n","                 'Provision_PT_737E_Security_Camera',\n","                 'Danmini_Doorbell',\n","                 'Ennio_Doorbell',\n","                 'Ecobee_Thermostat',\n","                 'Samsung_SNH_1011_N_Webcam',\n","                 'Philips_B120N10_Baby_Monitor']\n","#Device_Listing = ['Provision_PT_838_Security_Camera', 'Ecobee_Thermostat']\n","\n","\n","Malware_Listing = ['Mirai','Bashlite']\n","#Malware_Listing = ['Bashlite']\n","                   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqTGpDNOx1xz"},"source":["# Setting Variables\n"]},{"cell_type":"code","metadata":{"id":"5pUoV7fNqTHh"},"source":["# Environment Variables\n","\n","# Known_Devices = ['SimpleHome_XCS7_1002_WHT_Security_Camera']\n","# Unknown_Devices = ['Philips_B120N10_Baby_Monitor']\n","\n","# At the moment, it is not expected that both of the following booleans shall be true at the same time. Our analysis is for a single malware at a time.\n","# Run_For_Malware_Mirai = 1\n","# Run_For_Malware_Bashlite = 0\n","\n","# Fisher Score Variables\n","fisher_score_use_top_n_features = 115 #(max value is 115, reducing this value will reduce the total pool of features to use in training)\n","use_features_with_fisher_score_greater_than = 0 #(when set to 0, will use all top_n features allowed in above variable. For none zero values, will only use features from the top_n variable above\n","                                                # whose fisher score is greater than the value set in this variable.)\n","\n","# This name shall be used to generate relevant save file names at relevant paths\n","# savefilename='Known-SimpleHomeCamera_Unknown-Provision'\n","# transfer_savefilename='Transfer-Known-SimpleHomeCamera_Unknown-Provision'\n","\n","\n","#checkpoint_filepath=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run/original-checkpoint.h5\"\n","#transfer_learning_checkpoint_filepath=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run/transfer-checkpoint.h5\"\n","\n","#results_file_path='/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run/looped_run_results.txt'\n","#F_Score_File='/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run/F_score_file.txt'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Functions"],"metadata":{"id":"IKrJqD9j8h5O"}},{"cell_type":"code","source":["### Results file writing function\n","\n","def createAndOpen(filepath, filename, mode):\n","  os.makedirs(filepath, exist_ok=True)\n","  return open(filename, mode)\n","\n","def results_file_writing(data):\n","  resultsfile = createAndOpen(results_file_path, results_file_name, 'a+')\n","  resultsfile.write(data)\n","  resultsfile.close()\n","\n","def buffer_results_file_writing():\n","  s = buffer.getvalue()\n","  resultsfile = createAndOpen(results_file_path, results_file_name, 'a+')\n","  resultsfile.write(s)\n","  resultsfile.close() \n","  buffer.close()\n","\n","\n","def tl_results_file_writing(data):\n","  resultsfile = createAndOpen(tl_results_file_path, tl_results_file_name, 'a+')\n","  resultsfile.write(data)\n","  resultsfile.close()\n","\n","def tl_buffer_results_file_writing():\n","  s = buffer.getvalue()\n","  resultsfile = createAndOpen(tl_results_file_path, tl_results_file_name, 'a+')\n","  resultsfile.write(s)\n","  resultsfile.close() \n","  buffer.close()\n","\n","### Write Buffer\n","\n","buffer = io.StringIO()"],"metadata":{"id":"js3VDkPf2vbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fisher_score(benigndf, attackdf, devicename, F_Score_File):\n","  scaled_df_fisher = benigndf.append(attackdf.sample(n=benigndf.shape[0]))\n","  \n","  #print(scaled_df_fisher.shape)\n","  scored = [] # declare a list\n","  indices = {} # declare two dictionaries, purpose unknown\n","  shps = {}\n","  classes = ['benign','attack']\n","\n","  for cl in classes:\n","      indices[cl] = scaled_df_fisher['class'] == cl # Now here, above created Fisher dataframe shall have two classes only.\n","                                           # so half of the time the comparison output shall be true and false\n","                                           # for the rest.\n","                                           # It creates a Pandas series\n","      shps[cl] = scaled_df_fisher[indices[cl]].shape[0] # dictionary contains the number of rows of benign traffic and the\n","                                               # number of rows for the attack traffic\n","\n","  for col in scaled_df_fisher.columns: # Loop through all the columns of the Fisher DataFrame\n","      if col == 'class':  # if the column is that of \"Class\", then skip it.\n","          continue\n","      num = 0\n","      den = 0\n","      m = scaled_df_fisher[col].mean() # For the column under the current iteration, find the mean value.\n","                            # no, nothing strange about this. We are finding out the mean of each field/column\n","                            # in the dataset.\n","    \n","      for cl in classes: # For each column (this essentially means that we are considering that column at the moment)\n","                       # calculate the numerator and the denominator values for the Fisher score per class.\n","          num += (shps[cl] / scaled_df_fisher.shape[0]) * (m - scaled_df_fisher[indices[cl]][col].mean())**2\n","                # shps[cl] --> e.g if shps['benign'] then number of rows in it shall be 33032\n","                # (33032/66064) * ([mean-of-that-whole-column] - mean-of-rows-whose class was cl)**2\n","          den += (shps[cl] / scaled_df_fisher.shape[0]) * scaled_df_fisher[indices[cl]][col].var()\n","                # shps[cl] --> e.g if shps['benign'] then number of rows in it shall be 33032\n","                # (33032/66064) * (variance-of-rows-whose class was cl)\n","        \n","      score = {'feature': col, 'score': num / den}\n","      scored.append(score)\n","      #print(score)\n","  scored.sort(key=lambda x: x['score'], reverse=True)\n","  #scored[:115] #scored is a list of dictionaries    \n","\n","\n","  # Write down the calculated F-scores in a file.\n","  with open(F_Score_File, 'a+') as file:\n","      file.write('\\n\\n\\n============================\\n ' + str(devicename) + '\\n============================')\n","      lines = ['\\nFeature,Score\\n']\n","      for s in scored:\n","          lines.append(s['feature'] + ',' + \"{0:.2f}\".format(s['score']) + '\\n')\n","      file.writelines(lines)\n","      file.close()\n","\n","  return scored"],"metadata":{"id":"UgOvYlhy8l4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def anomaly_detect_func(device_benign_test, device_attack, known_device, mse_max, quantile_mse_max, model, scaler, fs, confusion_matrix_figure):\n","  \n","  results_file_writing('\\n\\n=======\\n Attempting Anomaly detection')\n","  \n","  anomaly_detect_01_df_benign = device_benign_test[fs] # Creating Labeled datasets\n","  anomaly_detect_01_df_benign['malicious'] = 0\n","\n","  # Removing randomness bias\n","  # df_malicious = df_known_device_attack.sample(n=df_known_device_benign_test.shape[0], random_state=406)[fs] # Keeping equal parts of benign / malicious data\n","  anomaly_detect_01_df_malicious = device_attack.sample(n=device_benign_test.shape[0])[fs] # Keeping equal parts of benign / malicious data\n","  anomaly_detect_01_df_malicious['malicious'] = 1\n","\n","  anomaly_detect_01_df = anomaly_detect_01_df_benign.append(anomaly_detect_01_df_malicious)\n","  anomaly_detect_01_X_test = anomaly_detect_01_df.drop(columns=['malicious']).values\n","  anomaly_detect_01_Y_test = anomaly_detect_01_df['malicious'] # This shall form the ground truth series of values.\n","  #print(Y_test)\n","\n","  #for threshold in [mse_max, quantile_mse.max()]:\n","  for threshold in [mse_max]:\n","    m = AnomalyModel(model , threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    results_file_writing('\\nTest-----------------\\n')\n","    #print(f'suggensted threshodl n {best_n}')\n","    results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_acc))\n","\n","    results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_prec))\n","\n","    results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_recall))\n","\n","    results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    results_file_writing(str(anomaly_detect_01_cm))  \n","\n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)\n","    plt.show()\n","\n","  \n","  return [anomaly_detect_01_acc, anomaly_detect_01_X_test, anomaly_detect_01_Y_test, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]"],"metadata":{"id":"KTDcPO2TixS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def best_results_finder(base_acc, mse, quantile_mse, model, scaler, malware, known_device, anomaly_detect_01_X_test, anomaly_detect_01_Y_test, confusion_matrix_figure):\n","\n","  results_file_writing('\\n\\n=======\\n Attempting to Find the Best Threshold')\n","  \n","  #print('Starting Accuracy')\n","  starting_accuracy = base_acc\n","  #print(base_acc)\n","\n","  new_percentile = 0.995\n","  some_increase_found = False\n","\n","  best_acc = starting_accuracy\n","  best_percentile = 0.995\n","\n","  for test_percentile in [0.995, 0.99, 0.985, 0.98, 0.975, 0.97, 0.965, 0.96, 0.955, 0.95, 0.945, 0.94, 0.935, 0.93, 0.925, 0.92, 0.915, 0.91, 0.905, 0.90]:\n","    print(\"Iterating through percentiles to find best threshold\")\n","  \n","    threshold = mse[mse < mse.quantile(q=test_percentile)].max()\n","    results_file_writing(str('\\nCurrent Percentile: ' + str(test_percentile)))\n","    results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str('\\n new_acc: ' + str(new_acc) + ' ... new_precision: ' + str(new_precision)))\n","\n","    if new_acc > best_acc:\n","      results_file_writing('\\n new_acc > best_acc \\n\\n') \n","      best_acc = new_acc\n","      best_percentile = test_percentile\n","    else:\n","      results_file_writing('\\n NEW_ACC <= BEST_ACC \\n\\n')\n","\n","\n","  #if new_acc > starting_accuracy:\n","  if best_acc > starting_accuracy:\n","\n","    results_file_writing('\\n\\n=======\\n Found a Better Quantile, Results are: \\n')\n","\n","    #threshold = mse[mse < mse.quantile(q=previous_percentile)].max()\n","    threshold = mse[mse < mse.quantile(q=best_percentile)].max()\n","    #results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","\n","    results_file_writing('\\n ------ Results ------\\n')\n","\n","    #results_file_writing(str('\\nPercentile: ' + str(previous_percentile)))\n","    results_file_writing(str('\\nPercentile: ' + str(best_percentile)))\n","    results_file_writing(str('\\n Threshold: ' + str(threshold)))\n","    \n","    #print(f'suggensted threshodl n {best_n}')\n","    results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_acc))\n","\n","    results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_prec))\n","\n","    results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_recall))\n","\n","    results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    results_file_writing(str(anomaly_detect_01_cm))  \n","\n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)\n","    plt.show()\n","\n","    return [threshold, best_percentile, anomaly_detect_01_acc, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]\n","\n","  else:\n","    results_file_writing('\\n\\n=======\\n DID NOT find a Better Quantile, Results are: \\n')\n","\n","    threshold = mse[mse < mse.quantile(q=1)].max()\n","    #results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","\n","    results_file_writing('\\n ------ Results ------\\n')\n","    results_file_writing('\\nPercentile: 1.0 (global setting)' )\n","\n","    results_file_writing(str('\\n Threshold: ' + str(threshold)))\n","\n","    #print(f'suggensted threshodl n {best_n}')\n","    results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_acc))\n","\n","    results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_prec))\n","\n","    results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_recall))\n","\n","    results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    results_file_writing(str(anomaly_detect_01_cm))  \n"," \n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)    \n","    plt.show()\n","\n","    return [threshold, 1.0, anomaly_detect_01_acc, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]\n","\n","\n","'''\n","  while True:\n","    print(\"entering while loop\")\n","    if new_percentile <= 0.9:\n","      results_file_writing('\\nreached quite  low percentile of 0.90 ... Aborting\\n')\n","      anomaly_detect_01_chosen_threshold = quantile_mse.max()\n","      results_file_writing('\\nselected percentile for threshold is 1.0\\n')\n","      results_file_writing(str('\\nselected threshold is: ' + str(anomaly_detect_01_chosen_threshold)))    \n","      break\n","    threshold = mse[mse < mse.quantile(q=new_percentile)].max()\n","    results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    results_file_writing(str('\\n new_acc: ' + str(new_acc) + ' ... new_precision: ' + str(new_precision)))\n","    if new_acc > base_acc:\n","      results_file_writing('\\n new_acc > base_acc') \n","      base_acc = new_acc\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      results_file_writing(str('\\n Next Percentile to test ' + str(new_percentile) + '\\n-------------------\\n'))\n","      some_increase_found = True\n","    elif new_acc < base_acc:\n","      results_file_writing('\\n NEW-ACC < BASE-ACC')\n","      if some_increase_found:\n","        results_file_writing('\\n New accuracy is lower than previous, stopping... ')\n","        results_file_writing(str('\\n selected percentile for threshold is: ' + str(previous_percentile)))\n","        results_file_writing('\\n selected threshold is: ')\n","        results_file_writing(str(threshold))\n","        anomaly_detect_01_chosen_threshold = threshold\n","        break\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      results_file_writing(str('\\n Next Percentile to test ' + str(new_percentile)))\n","      continue\n","    else:\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      results_file_writing(str('\\n Next Percentile to test: ' + str(new_percentile)))\n","'''\n","\n"],"metadata":{"id":"mX3qVm4a6rfu","executionInfo":{"status":"ok","timestamp":1643527955838,"user_tz":-300,"elapsed":623,"user":{"displayName":"Unsub Shafiq","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07945986632191365791"}},"colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"15a39793-63d1-479c-a31c-07558f8d380e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n  while True:\\n    print(\"entering while loop\")\\n    if new_percentile <= 0.9:\\n      results_file_writing(\\'\\nreached quite  low percentile of 0.90 ... Aborting\\n\\')\\n      anomaly_detect_01_chosen_threshold = quantile_mse.max()\\n      results_file_writing(\\'\\nselected percentile for threshold is 1.0\\n\\')\\n      results_file_writing(str(\\'\\nselected threshold is: \\' + str(anomaly_detect_01_chosen_threshold)))    \\n      break\\n    threshold = mse[mse < mse.quantile(q=new_percentile)].max()\\n    results_file_writing(str(\\'\\nCurrent Threshold: \\' + str(threshold)))\\n    m = AnomalyModel(model, threshold, scaler)\\n    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\\n    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\\n    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\\n    results_file_writing(str(\\'\\n new_acc: \\' + str(new_acc) + \\' ... new_precision: \\' + str(new_precision)))\\n    if new_acc > base_acc:\\n      results_file_writing(\\'\\n new_acc > base_acc\\') \\n      base_acc = new_acc\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      results_file_writing(str(\\'\\n Next Percentile to test \\' + str(new_percentile) + \\'\\n-------------------\\n\\'))\\n      some_increase_found = True\\n    elif new_acc < base_acc:\\n      results_file_writing(\\'\\n NEW-ACC < BASE-ACC\\')\\n      if some_increase_found:\\n        results_file_writing(\\'\\n New accuracy is lower than previous, stopping... \\')\\n        results_file_writing(str(\\'\\n selected percentile for threshold is: \\' + str(previous_percentile)))\\n        results_file_writing(\\'\\n selected threshold is: \\')\\n        results_file_writing(str(threshold))\\n        anomaly_detect_01_chosen_threshold = threshold\\n        break\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      results_file_writing(str(\\'\\n Next Percentile to test \\' + str(new_percentile)))\\n      continue\\n    else:\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      results_file_writing(str(\\'\\n Next Percentile to test: \\' + str(new_percentile)))\\n'"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["========================\n","========================"],"metadata":{"id":"xs61gu8gO0Y3"}},{"cell_type":"code","source":["def unknown_anomaly_detect_func(device_benign_test, device_attack, known_device, mse_max, model, scaler, fs, confusion_matrix_figure):\n","  \n","  tl_results_file_writing('\\n\\n=======\\n Attempting Anomaly detection - Function: Unknown Anomaly Detect')\n","  \n","  anomaly_detect_01_df_benign = device_benign_test[fs] # Creating Labeled datasets\n","  anomaly_detect_01_df_benign['malicious'] = 0\n","\n","  # Removing randomness bias\n","  # df_malicious = df_known_device_attack.sample(n=df_known_device_benign_test.shape[0], random_state=406)[fs] # Keeping equal parts of benign / malicious data\n","  anomaly_detect_01_df_malicious = device_attack.sample(n=device_benign_test.shape[0])[fs] # Keeping equal parts of benign / malicious data\n","  anomaly_detect_01_df_malicious['malicious'] = 1\n","\n","  anomaly_detect_01_df = anomaly_detect_01_df_benign.append(anomaly_detect_01_df_malicious)\n","  anomaly_detect_01_X_test = anomaly_detect_01_df.drop(columns=['malicious']).values\n","  anomaly_detect_01_Y_test = anomaly_detect_01_df['malicious'] # This shall form the ground truth series of values.\n","  #print(Y_test)\n","\n","  #for threshold in [mse_max, quantile_mse.max()]:\n","  for threshold in [mse_max]:\n","    m = AnomalyModel(model , threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    tl_results_file_writing('\\nTest-----------------\\n')\n","    #print(f'suggensted threshodl n {best_n}')\n","    tl_results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_acc))\n","\n","    tl_results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_prec))\n","\n","    tl_results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_recall))\n","\n","    tl_results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    tl_results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    tl_results_file_writing(str(anomaly_detect_01_cm))  \n","\n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)\n","    plt.show()\n","\n","  \n","  return [anomaly_detect_01_acc, anomaly_detect_01_X_test, anomaly_detect_01_Y_test, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]"],"metadata":{"id":"bkhHZ4juO4O0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tl_best_results_finder(base_acc, mse, quantile_mse, model, scaler, malware, known_device, anomaly_detect_01_X_test, anomaly_detect_01_Y_test, confusion_matrix_figure):\n","\n","  tl_results_file_writing('\\n\\n=======\\n Attempting to Find the Best Threshold')\n","  \n","  #print('Starting Accuracy')\n","  starting_accuracy = base_acc\n","  #print(base_acc)\n","\n","  new_percentile = 0.995\n","  some_increase_found = False\n","\n","  best_acc = starting_accuracy\n","  best_percentile = 0.995\n","\n","  for test_percentile in [0.995, 0.99, 0.985, 0.98, 0.975, 0.97, 0.965, 0.96, 0.955, 0.95, 0.945, 0.94, 0.935, 0.93, 0.925, 0.92, 0.915, 0.91, 0.905, 0.90]:\n","    print(\"Iterating through percentiles to find best threshold\")\n","  \n","    threshold = mse[mse < mse.quantile(q=test_percentile)].max()\n","    tl_results_file_writing(str('\\nCurrent Percentile: ' + str(test_percentile)))\n","    tl_results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str('\\n new_acc: ' + str(new_acc) + ' ... new_precision: ' + str(new_precision)))\n","\n","    if new_acc > best_acc:\n","      tl_results_file_writing('\\n new_acc > best_acc \\n\\n') \n","      best_acc = new_acc\n","      best_percentile = test_percentile\n","    else:\n","      tl_results_file_writing('\\n NEW_ACC <= BEST_ACC \\n\\n')\n","\n","\n","  #if new_acc > starting_accuracy:\n","  if best_acc > starting_accuracy:\n","\n","    tl_results_file_writing('\\n\\n=======\\n Found a Better Quantile, Results are: \\n')\n","\n","    #threshold = mse[mse < mse.quantile(q=previous_percentile)].max()\n","    threshold = mse[mse < mse.quantile(q=best_percentile)].max()\n","    #results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","\n","    tl_results_file_writing('\\n ------ Results ------\\n')\n","\n","    #tl_results_file_writing(str('\\nPercentile: ' + str(previous_percentile)))\n","    tl_results_file_writing(str('\\nPercentile: ' + str(best_percentile)))\n","    tl_results_file_writing(str('\\n Threshold: ' + str(threshold)))\n","    \n","    #print(f'suggensted threshodl n {best_n}')\n","    tl_results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_acc))\n","\n","    tl_results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_prec))\n","\n","    tl_results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_recall))\n","\n","    tl_results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    tl_results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    tl_results_file_writing(str(anomaly_detect_01_cm))  \n","\n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)\n","    plt.show()\n","\n","    return [threshold, best_percentile, anomaly_detect_01_acc, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]\n","\n","  else:\n","    tl_results_file_writing('\\n\\n=======\\n DID NOT find a Better Quantile, Results are: \\n')\n","\n","    threshold = mse[mse < mse.quantile(q=1)].max()\n","    #results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","\n","    tl_results_file_writing('\\n ------ Results ------\\n')\n","    tl_results_file_writing('\\nPercentile: 1.0 (global setting)' )\n","\n","    tl_results_file_writing(str('\\n Threshold: ' + str(threshold)))\n","\n","    #print(f'suggensted threshodl n {best_n}')\n","    tl_results_file_writing('\\nAccuracy: ')\n","    anomaly_detect_01_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_acc))\n","\n","    tl_results_file_writing('\\nPrecision: ')\n","    anomaly_detect_01_prec = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_prec))\n","\n","    tl_results_file_writing('\\nRecall: ')\n","    anomaly_detect_01_recall = recall_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_recall))\n","\n","    tl_results_file_writing('\\nF1_Score: ')\n","    anomaly_detect_01_f1score = f1_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str(anomaly_detect_01_f1score))\n","\n","    tl_results_file_writing('\\nCM :')\n","    anomaly_detect_01_cm = confusion_matrix(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred, labels=[0,1])\n","    tl_results_file_writing(str(anomaly_detect_01_cm))  \n"," \n","    confusion_matrix_fig=confusion_matrix_figure\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(anomaly_detect_01_cm)\n","    plt.title('Confusion matrix')\n","    fig.colorbar(cax)\n","    labels=['0','1']\n","    ax.set_xticklabels([''] + labels)\n","    ax.set_yticklabels([''] + labels)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(confusion_matrix_fig)    \n","    plt.show()\n","\n","    return [threshold, 1.0, anomaly_detect_01_acc, anomaly_detect_01_prec, anomaly_detect_01_recall, anomaly_detect_01_f1score]\n","\n","'''\n","  while True:\n","    print(\"entering while loop\")\n","    if new_percentile <= 0.9:\n","      tl_results_file_writing('\\nreached quite  low percentile of 0.90 ... Aborting\\n')\n","      anomaly_detect_01_chosen_threshold = quantile_mse.max()\n","      tl_results_file_writing('\\nselected percentile for threshold is 1.0\\n')\n","      tl_results_file_writing(str('\\nselected threshold is: ' + str(anomaly_detect_01_chosen_threshold)))    \n","      break\n","    threshold = mse[mse < mse.quantile(q=new_percentile)].max()\n","    tl_results_file_writing(str('\\nCurrent Threshold: ' + str(threshold)))\n","    m = AnomalyModel(model, threshold, scaler)\n","    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\n","    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\n","    tl_results_file_writing(str('\\n new_acc: ' + str(new_acc) + ' ... new_precision: ' + str(new_precision)))\n","    if new_acc > base_acc:\n","      tl_results_file_writing('\\n new_acc > base_acc') \n","      base_acc = new_acc\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      tl_results_file_writing(str('\\n Next Percentile to test ' + str(new_percentile) + '\\n-------------------\\n'))\n","      some_increase_found = True\n","    elif new_acc < base_acc:\n","      tl_results_file_writing('\\n NEW-ACC < BASE-ACC')\n","      if some_increase_found:\n","        tl_results_file_writing('\\n New accuracy is lower than previous, stopping... ')\n","        tl_results_file_writing(str('\\n selected percentile for threshold is: ' + str(previous_percentile)))\n","        tl_results_file_writing('\\n selected threshold is: ')\n","        tl_results_file_writing(str(threshold))\n","        anomaly_detect_01_chosen_threshold = threshold\n","        break\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      tl_results_file_writing(str('\\n Next Percentile to test ' + str(new_percentile)))\n","      continue\n","    else:\n","      previous_percentile = new_percentile\n","      new_percentile = new_percentile - 0.005\n","      tl_results_file_writing(str('\\n Next Percentile to test: ' + str(new_percentile)))\n","\n","\n","'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"8y45Ay_LN1Wg","executionInfo":{"status":"ok","timestamp":1643527957300,"user_tz":-300,"elapsed":637,"user":{"displayName":"Unsub Shafiq","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07945986632191365791"}},"outputId":"4cbfc71f-e0a1-46e7-f4b4-89f9e0146222"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n  while True:\\n    print(\"entering while loop\")\\n    if new_percentile <= 0.9:\\n      tl_results_file_writing(\\'\\nreached quite  low percentile of 0.90 ... Aborting\\n\\')\\n      anomaly_detect_01_chosen_threshold = quantile_mse.max()\\n      tl_results_file_writing(\\'\\nselected percentile for threshold is 1.0\\n\\')\\n      tl_results_file_writing(str(\\'\\nselected threshold is: \\' + str(anomaly_detect_01_chosen_threshold)))    \\n      break\\n    threshold = mse[mse < mse.quantile(q=new_percentile)].max()\\n    tl_results_file_writing(str(\\'\\nCurrent Threshold: \\' + str(threshold)))\\n    m = AnomalyModel(model, threshold, scaler)\\n    anomaly_detect_01_Y_pred = m.predict(anomaly_detect_01_X_test)\\n    new_acc = accuracy_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\\n    new_precision = precision_score(anomaly_detect_01_Y_test, anomaly_detect_01_Y_pred)\\n    tl_results_file_writing(str(\\'\\n new_acc: \\' + str(new_acc) + \\' ... new_precision: \\' + str(new_precision)))\\n    if new_acc > base_acc:\\n      tl_results_file_writing(\\'\\n new_acc > base_acc\\') \\n      base_acc = new_acc\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      tl_results_file_writing(str(\\'\\n Next Percentile to test \\' + str(new_percentile) + \\'\\n-------------------\\n\\'))\\n      some_increase_found = True\\n    elif new_acc < base_acc:\\n      tl_results_file_writing(\\'\\n NEW-ACC < BASE-ACC\\')\\n      if some_increase_found:\\n        tl_results_file_writing(\\'\\n New accuracy is lower than previous, stopping... \\')\\n        tl_results_file_writing(str(\\'\\n selected percentile for threshold is: \\' + str(previous_percentile)))\\n        tl_results_file_writing(\\'\\n selected threshold is: \\')\\n        tl_results_file_writing(str(threshold))\\n        anomaly_detect_01_chosen_threshold = threshold\\n        break\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      tl_results_file_writing(str(\\'\\n Next Percentile to test \\' + str(new_percentile)))\\n      continue\\n    else:\\n      previous_percentile = new_percentile\\n      new_percentile = new_percentile - 0.005\\n      tl_results_file_writing(str(\\'\\n Next Percentile to test: \\' + str(new_percentile)))\\n\\n\\n'"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#### AutoEncoder Model"],"metadata":{"id":"OzjQK3PS_YeF"}},{"cell_type":"code","source":["# Now creating a ____________ model\n","def create_model(input_dim):\n","    inp = Input(shape=(input_dim,))\n","    encoder = Dense(int(math.ceil(0.80 * input_dim)), activation=\"tanh\")(inp)\n","    encoder = Dense(int(math.ceil(0.60 * input_dim)), activation=\"tanh\")(encoder)\n","    encoder = Dense(int(math.ceil(0.40 * input_dim)), activation=\"tanh\")(encoder)\n","    encoder = Dense(int(math.ceil(0.20 * input_dim)), activation=\"tanh\")(encoder)\n","    decoder = Dense(int(math.ceil(0.40 * input_dim)), activation=\"tanh\")(encoder)\n","    decoder = Dense(int(math.ceil(0.60 * input_dim)), activation=\"tanh\")(decoder)\n","    decoder = Dense(int(math.ceil(0.80 * input_dim)), activation=\"tanh\")(decoder)\n","    decoder = Dense(input_dim)(decoder)\n","    return Model(inp, decoder)"],"metadata":{"id":"cVZJMcvP_bAv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Anomaly Detection Class"],"metadata":{"id":"oK-1JXSieZmR"}},{"cell_type":"code","source":[" #A Class definition for executing predictions\n","class AnomalyModel:\n","    def __init__(self, model, threshold, scaler):\n","        self.model = model\n","        self.threshold = threshold\n","        self.scaler = scaler\n","\n","    def predict(self, x):\n","        x_pred = self.model.predict(x)\n","        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n","        y_pred = mse > self.threshold\n","        return y_pred.astype(int)"],"metadata":{"id":"MGDDJ3IEec1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Making a Giant Loop"],"metadata":{"id":"fs9_r1ttx6FY"}},{"cell_type":"code","source":["for malware in Malware_Listing: # iterate for each malware.\n","\n","  \n","  for known_device in Device_Listing:\n","\n","    ### Defining file location variables\n","\n","    checkpoint_filepath=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/original-checkpoint.h5\"\n","    results_file_path=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}\"\n","    results_file_name=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/looped_run_results.txt\"\n","    Known_F_Score_File=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/F_score_file.txt\"\n","    \n","    known_device_confusion_matrix_figure_percentile_1=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/anomaly-detect-CM-percentile-1.png\"\n","    known_device_confusion_matrix_figure_best_percentile=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/anomaly-detect-CM-percentile-best.png\"\n","    \n","    results_file_writing(str('\\n\\n\\n ==== \\n LOOPING FOR MALWARE: '  + str(malware) + '\\n'))\n","    results_file_writing('KNOWN DEVICE: ' + str(known_device) + '\\n')\n","\n","    ### Gathering Benign data of the known device\n","\n","    filepaths = []\n","    print(known_device)\n","    benign_path = f\"/content/drive/My Drive/thesis-unsub/data/{known_device}/benign_traffic.csv\"\n","    filepaths.append(benign_path)\n","\n","    df_known_device_benign = pd.concat((pd.read_csv(f) for f in filepaths), ignore_index=True)\n","    results_file_writing(\"\\n Benign DataFrame Information\\n------\")\n","    \n","    buffer = io.StringIO()\n","    df_known_device_benign.info(buf=buffer)\n","    buffer_results_file_writing()\n","    results_file_writing('\\n\\n')\n","\n","    ### Gathering Attack data of the known device\n","\n","    if malware == \"Mirai\":\n","      \n","      if known_device == \"Ennio_Doorbell\":\n","        continue\n","      if known_device == \"Samsung_SNH_1011_N_Webcam\":\n","        continue\n","\n","      results_file_writing(\"\\n\\n LOADING ATTACK DATA OF KNOWN DEVICE AGAINST MALWARE: MIRAI\\n\")\n","      \n","      Mirai_Filepaths = []\n","      attack_path = f\"/content/drive/My Drive/thesis-unsub/data/{known_device}/mirai_attacks/\"\n","        \n","      for files in ['ack.csv', 'scan.csv', 'syn.csv', 'udp.csv', 'udpplain.csv']:\n","        filepath = attack_path + str(files)\n","        Mirai_Filepaths.append(filepath)\n","\n","      results_file_writing(str(Mirai_Filepaths))\n","\n","      df_known_device_attack= pd.concat((pd.read_csv(f) for f in Mirai_Filepaths), ignore_index=True)\n","      \n","      results_file_writing(\"\\n Attack DataFrame Information\\n------\")\n","      buffer = io.StringIO()\n","      df_known_device_attack.info(buf=buffer)\n","      buffer_results_file_writing()\n","      results_file_writing('\\n\\n')    \n","\n","    elif malware == \"Bashlite\":\n","      results_file_writing(\"\\n\\n LOADING ATTACK DATA OF KNOWN DEVICE AGAINST MALWARE: BASHLITE\\n\")\n","\n","      Bashlite_Filepaths = []\n","      \n","      attack_path = f\"/content/drive/My Drive/thesis-unsub/data/{known_device}/gafgyt_attacks/\"\n","      \n","      for files in ['combo.csv', 'junk.csv', 'scan.csv', 'tcp.csv', 'udp.csv']:\n","        filepath = attack_path + str(files)\n","        Bashlite_Filepaths.append(filepath)\n","\n","      results_file_writing(str(Bashlite_Filepaths))\n","\n","      df_known_device_attack = pd.concat((pd.read_csv(f) for f in Bashlite_Filepaths), ignore_index=True)\n","      results_file_writing(\"\\n Attack DataFrame Information\\n------\")\n","      \n","      buffer = io.StringIO()\n","      df_known_device_attack.info(buf=buffer)\n","      buffer_results_file_writing()\n","      results_file_writing('\\n\\n')\n","\n","\n","      ### Splitting the benign dataset of the Known dataset.\n","\n","    results_file_writing(\"\\n\\n\\n Splitting Benign Data into 3 parts for training, optimization and test in a 60/20/20 split\\n\")\n","\n","    df_known_device_benign_train, df_known_device_benign_opt, df_known_device_benign_test = np.split(df_known_device_benign.sample(frac=1), [int(3/5*len(df_known_device_benign)), int(4/5*len(df_known_device_benign))])\n","\n","    results_file_writing(\"Split Information\\n\")\n","    results_file_writing(\"df_known_device_benign_train: \" + str(df_known_device_benign_train.shape) + \"\\n\")\n","    results_file_writing(\"df_known_device_benign_opt:   \" + str(df_known_device_benign_opt.shape) + \"\\n\")\n","    results_file_writing(\"df_known_device_benign_test:  \" + str(df_known_device_benign_test.shape) + \"\\n\")\n","\n","\n","    results_file_writing(\"\\n\\n Information about the Split\\nTraining Data\\n---\")\n","    buffer = io.StringIO()\n","    df_known_device_benign_train.info(buf=buffer)\n","    buffer_results_file_writing()\n","\n","    results_file_writing(\"\\n Optimization Data\\n---\")\n","    buffer = io.StringIO()\n","    df_known_device_benign_opt.info(buf=buffer)\n","    buffer_results_file_writing()\n","\n","    results_file_writing(\"\\n Test Data \\n---\")\n","    buffer = io.StringIO()\n","    df_known_device_benign_test.info(buf=buffer)\n","    buffer_results_file_writing() \n","\n","    ### Scaling the bengin and attack datasets of the known device.\n","    col_list = []\n","    for col in df_known_device_benign_train.columns:\n","      col_list.append(col)\n","\n","    scaler = MinMaxScaler()\n","    scaled_df_known_device_benign_train = scaler.fit_transform(df_known_device_benign_train)\n","    scaled_df_known_device_benign_opt = scaler.transform(df_known_device_benign_opt)\n","    scaled_df_known_device_benign_test = scaler.transform(df_known_device_benign_test)\n","    scaled_df_known_device_attack = scaler.transform(df_known_device_attack)\n","    #Converting NumPy arrays back to Pandas DataFrames\n","    scaled_df_known_device_benign_train = pd.DataFrame(scaled_df_known_device_benign_train, columns=col_list)\n","    scaled_df_known_device_benign_opt = pd.DataFrame(scaled_df_known_device_benign_opt, columns=col_list)\n","    scaled_df_known_device_benign_test = pd.DataFrame(scaled_df_known_device_benign_test, columns=col_list)\n","    scaled_df_known_device_attack = pd.DataFrame(scaled_df_known_device_attack, columns=col_list)    \n","\n","\n","    ### Labelling the data.\n","    scaled_df_known_device_attack['class'] = 'attack'\n","    scaled_df_known_device_benign_train['class'] = 'benign'\n","    scaled_df_known_device_benign_opt['class'] = 'benign'\n","    scaled_df_known_device_benign_test['class'] = 'benign'    \n","\n","    ### FisherScoring Function\n","    scores = fisher_score(scaled_df_known_device_benign_train, scaled_df_known_device_attack, known_device, Known_F_Score_File)\n","\n","    results_file_writing('\\n\\n\\n --> Calculated the Fisher Score for known Device, see the F_Score_file')\n","\n","    ### Model Training Time\n","    results_file_writing('\\n\\n\\n --> Starting AutoEncoder Model Training')\n","    for top_n_features in [fisher_score_use_top_n_features]:\n","      fs = []\n","      for it in scores[:top_n_features]:\n","        if it['score'] > use_features_with_fisher_score_greater_than:  \n","          fs.append(it['feature'])    \n","\n","      features_to_be_used = len(fs)\n","      DF_BENIGN_TRAIN = scaled_df_known_device_benign_train[fs]\n","      DF_BENIGN_OPT = scaled_df_known_device_benign_opt[fs]\n","      DF_BENIGN_TEST = scaled_df_known_device_benign_test[fs]\n","\n","      model = create_model(len(fs))\n","      model.compile(loss=\"mean_squared_error\",\n","                    optimizer=\"adam\")\n","    \n","      Initial_Weights = model.get_weights()\n","\n","      cp = ModelCheckpoint(filepath=checkpoint_filepath,\n","                                  monitor='val_loss',\n","                               save_best_only=True,\n","                               verbose=1)\n","      es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","      start = time.time()\n","      epochs = 100\n","      history = model.fit(DF_BENIGN_TRAIN, DF_BENIGN_TRAIN,\n","                    epochs=epochs,\n","                    validation_data=(DF_BENIGN_OPT, DF_BENIGN_OPT),\n","                    verbose=1,\n","                    callbacks=[cp, es])\n","      end = time.time()\n","      results_file_writing('\\n\\n ----> Model Training Time Is: ')\n","      results_file_writing(str(end - start))\n","      results_file_writing('\\n\\n')\n","\n","      with open(results_file_name, 'at') as f:\n","        with redirect_stdout(f):\n","          model.summary()\n","      f.close()\n","\n","      original_model_path=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/model.h5\"\n","      model.save(original_model_path)\n","\n","    original_model_plot_path=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/training-plot.png\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Opt'], loc='upper left')\n","    plt.savefig(original_model_plot_path)    \n","    #plt.show()\n","\n","    ### Defining Anomaly Error Threshold\n","\n","    results_file_writing('\\n\\n  <<  Defining Anomaly Threshold  >>  \\n\\n')\n","    \n","    df_benign_known_device_test_predictions = model.predict(scaled_df_known_device_benign_test[fs])\n","    difference = scaled_df_known_device_benign_test[fs] - df_benign_known_device_test_predictions\n","    \n","    mse = np.mean(np.power(scaled_df_known_device_benign_test[fs] - df_benign_known_device_test_predictions, 2), axis=1) # Mean-Squared-Error is calculated for each row,\n","    mean = mse.mean() # We calculate the mean of the whole series, that is the mean mse for all the benign test cases.\n","    std = mse.std() # And we calculate the standard deviation of the mse series, containing only the test cases.\n","\n","    mse = pd.Series(mse) #converting np array to dataframe series\n","\n","    results_file_writing(str(\"MIN of MSE: \" + str(mse.min())) + \"\\n\")\n","    results_file_writing(str(\"MAX of MSE: \" + str(mse.max())) + \"\\n\")\n","    results_file_writing(str(\"MEAN of MSE: \" + str(mean)) + \"\\n\")\n","    results_file_writing(str(\"STD of MSE:  \" + str(std)) + \"\\n\")\n","\n","    mse_min = mse.min()\n","    mse_max = mse.max()\n","    results_file_writing(str(\"\\nMax Threshold = MSE_MAX: \" + str(mse_max))  + \"\\n\")\n","\n","    max_std_multiplier = int((mse_max - mean) / std)\n","    results_file_writing(str(\"\\nMAX_STD_Multiplier = \" + str(max_std_multiplier)) + \"\\n\")\n","\n","    original_model_error_distribution=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/error-distribution.png\"\n","    mse_plot = mse.plot.hist(bins=20, color='#0033cc')\n","    mse_plot.set_facecolor('#ffffff')\n","    mse_plot.set_xlim((mse_min, mse_max))\n","    mse_plot.set_ylim((0, mse[mse <= mse_max].count()))\n","    fig = mse_plot.get_figure()\n","    fig.savefig(original_model_error_distribution)\n","\n","    \n","    ### Doing the quantile MSE stuff\n","    results_file_writing('\\n\\n --> Doing the quantile MSE stuff\\n')\n","\n","    test_percentile = 1\n","    quantile_mse = mse[mse <= mse.quantile(q=test_percentile)]  # <= is important here\n","\n","    results_file_writing(str(\"MIN of QUANTILE_MSE: \" + str(quantile_mse.min())))\n","    results_file_writing(str(\"MAX of QUANTILE_MSE: \" + str(quantile_mse.max())))\n","    results_file_writing(str(\"MEAN of QUANTILE_MSE: \" + str(quantile_mse.mean())))\n","    results_file_writing(str(\"STD of QUNATILE_MSE:  \" + str(quantile_mse.std())))\n","    results_file_writing(str(\"Size of Series below 95th quantile: \" + str(quantile_mse.size)))\n","    results_file_writing(str(\"\\nSuggested Minimum Threshold = QUANTILE_MSE_MAX: \" + str(quantile_mse.max())))\n","\n","    min_std_multiplier = int((quantile_mse.max() - quantile_mse.mean()) / quantile_mse.std())\n","    results_file_writing(str(\"\\nMIN_STD_Multiplier = \" + str(min_std_multiplier)))\n","\n","    original_model_quantile_error_distribution=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/original-model/quantile-error-distribution.png\"\n","    quantile_mse_plot = quantile_mse.plot.hist(bins=20, color='#0033cc')\n","    quantile_mse_plot.set_facecolor('#ffffff')\n","    quantile_mse_plot.set_xlim((quantile_mse.min(), quantile_mse.max()))\n","    quantile_mse_plot.set_ylim((0, quantile_mse[quantile_mse <= quantile_mse.max()].count()))\n","    fig = mse_plot.get_figure()\n","    fig.savefig(original_model_quantile_error_distribution)\n","\n","\n","    ### Getting a base accuracy of the model using MSE-MAX threshold.\n","\n","    results = anomaly_detect_func(scaled_df_known_device_benign_test, scaled_df_known_device_attack, known_device, mse_max, quantile_mse.max(), model, scaler, fs, known_device_confusion_matrix_figure_percentile_1)\n","    base_acc = results[0]    \n","    anomaly_detect_01_X_test = results[1]\n","    anomaly_detect_01_Y_test  = results[2]\n","\n","\n","\n","    ### Finding the threshold with best scores\n","\n","    results_file_writing('\\n\\n <<--=== Finding Best Performning Threshold ===-->> \\n')\n","\n","    original_model_best_results = best_results_finder(base_acc, mse, quantile_mse, model, scaler, malware, known_device, anomaly_detect_01_X_test, anomaly_detect_01_Y_test, known_device_confusion_matrix_figure_best_percentile)\n","    original_model_best_threshold = original_model_best_results[0]\n","    original_model_best_percentile = original_model_best_results[1]\n","    original_model_best_accuracy = original_model_best_results[2]\n","    original_model_best_precision = original_model_best_results[3]\n","    original_model_best_recall = original_model_best_results[4]\n","    original_model_best_f1score = original_model_best_results[5]\n","\n","\n","    ### \n","    results_file_writing('\\n\\n\\n ===-->>> KNOWN DEVICE - ORIGINAL MODEL PERFORMANCE ')\n","    results_file_writing(str(known_device))\n","    results_file_writing('\\n')\n","    results_file_writing(str('ACCURACY: ' + str(original_model_best_accuracy)))\n","    results_file_writing('\\n')\n","    results_file_writing(str('PRECISION: ' + str(original_model_best_precision)))\n","    results_file_writing('\\n')\n","    results_file_writing(str('RECALL: ' + str(original_model_best_recall)))\n","    results_file_writing('\\n')\n","    results_file_writing(str('F1-SCORE: ' + str(original_model_best_f1score)))\n","    results_file_writing('\\n ------- \\n')\n","\n","    results_file_writing('\\n\\n\\n ===-->>> UNKNOWN DEVICE - TRANSFER MODEL PERFORMANCE ')\n","\n","\n","\n","\n","    ## <<<-- ============= TIME TO DO THE UNKOWN DEVICE ==========-->>>\n","\n","\n","\n","\n","\n","    for unknown_device in Device_Listing:\n","\n","      if known_device == unknown_device:\n","        print(\"unknown device is same as known device\")\n","        continue\n","      \n","\n","      ### Defining file location variables\n","\n","      transfer_learning_checkpoint_filepath=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/transfer-checkpoint.h5\"\n","      tl_results_file_path=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}\"\n","      tl_results_file_name=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/looped_run_results.txt\"\n","      Unknown_F_Score_File=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/Unknown_F_score_file.txt\"    \n","      unknown_device_confusion_matrix_figure_original_model_threshold=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/anomaly-detect-CM-originalModel-threshold.png\"\n","      unknown_device_confusion_matrix_figure_transfer_model_threshold=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/anomaly-detect-CM-TransferModel-threshold.png\"\n","      unknown_device_confusion_matrix_figure_transfer_model_best_percentile=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/anomaly-detect-CM-TransferModel-BestPercentile.png\"\n","      unknown_device_confusion_matrix_figure_transfer_model_final_performance=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/anomaly-detect-CM-TransferModel-FinalPerformance.png\"\n","\n","      tl_results_file_writing(str('\\n\\n\\n ==== \\n TRANSFER LEARINING  \\n ====: '  + str(malware) + '\\n'))\n","      tl_results_file_writing('UNKNOWN DEVICE: ' + str(unknown_device) + '\\n')\n","\n","      ### Gathering Benign data of the UNknown device\n","\n","      filepaths = []\n","      print(unknown_device)\n","      benign_path = f\"/content/drive/My Drive/thesis-unsub/data/{unknown_device}/benign_traffic.csv\"\n","      filepaths.append(benign_path)\n","\n","      df_unknown_device_benign = pd.concat((pd.read_csv(f) for f in filepaths), ignore_index=True)\n","      tl_results_file_writing(\"\\n Benign DataFrame Information\\n------\")\n","    \n","      buffer = io.StringIO()\n","      df_unknown_device_benign.info(buf=buffer)\n","      tl_buffer_results_file_writing()\n","      tl_results_file_writing('\\n\\n')\n","\n","      ### Gathering Attack data of the known device\n","\n","      if malware == \"Mirai\":\n","    \n","        if unknown_device == \"Ennio_Doorbell\":\n","          continue\n","        if unknown_device == \"Samsung_SNH_1011_N_Webcam\":\n","          continue\n","\n","        tl_results_file_writing(\"\\n\\n LOADING ATTACK DATA OF UNKNOWN DEVICE AGAINST MALWARE: MIRAI\\n\")\n","      \n","        Mirai_Filepaths = []\n","        attack_path = f\"/content/drive/My Drive/thesis-unsub/data/{unknown_device}/mirai_attacks/\"\n","       \n","        for files in ['ack.csv', 'scan.csv', 'syn.csv', 'udp.csv', 'udpplain.csv']:\n","          filepath = attack_path + str(files)\n","          Mirai_Filepaths.append(filepath)\n","\n","        tl_results_file_writing(str(Mirai_Filepaths))\n","\n","        df_unknown_device_attack = pd.concat((pd.read_csv(f) for f in Mirai_Filepaths), ignore_index=True)\n","      \n","        tl_results_file_writing('\\n\\n\\n Attack DataFrame Information\\n------')\n","        buffer = io.StringIO()\n","        df_unknown_device_attack.info(buf=buffer)\n","        tl_buffer_results_file_writing()\n","        tl_results_file_writing('\\n\\n')    \n","\n","      elif malware == \"Bashlite\":\n","        tl_results_file_writing(\"\\n\\n LOADING ATTACK DATA OF KNOWN DEVICE AGAINST MALWARE: BASHLITE\\n\")\n","\n","        Bashlite_Filepaths = []\n","      \n","        attack_path = f\"/content/drive/My Drive/thesis-unsub/data/{unknown_device}/gafgyt_attacks/\"\n","    \n","        for files in ['combo.csv', 'junk.csv', 'scan.csv', 'tcp.csv', 'udp.csv']:\n","          filepath = attack_path + str(files)\n","          Bashlite_Filepaths.append(filepath)\n","\n","        tl_results_file_writing(str(Bashlite_Filepaths))\n","\n","        df_unknown_device_attack = pd.concat((pd.read_csv(f) for f in Bashlite_Filepaths), ignore_index=True)\n","        tl_results_file_writing(\"\\n Attack DataFrame Information\\n------\")\n","      \n","        buffer = io.StringIO()\n","        df_unknown_device_attack.info(buf=buffer)\n","        tl_buffer_results_file_writing()\n","        tl_results_file_writing('\\n\\n')\n","\n","\n","      ### Scaling the datasets on unknown devices\n","      scaled_df_unknown_device_benign = scaler.transform(df_unknown_device_benign)\n","      scaled_df_unknown_device_attack = scaler.transform(df_unknown_device_attack)\n","      #Converting NumPy arrays back to Pandas DataFrames\n","      scaled_df_unknown_device_benign = pd.DataFrame(scaled_df_unknown_device_benign, columns=col_list)\n","      scaled_df_unknown_device_attack = pd.DataFrame(scaled_df_unknown_device_attack, columns=col_list)\n","\n","      scaled_df_unknown_device_attack['class'] = 'attack'\n","      scaled_df_unknown_device_benign['class'] = 'benign'\n","\n","\n","      #### Sampling the dataset for training, rest shall remain unseen to the model\n","      # sampling some data from the dataset. We shall sample this data to check if it improves the autoencoder accuracy.\n","      # and splitting this data into three parts, for training, optimization and validation.\n","\n","      length_unknown_device_benign = len(scaled_df_unknown_device_benign)\n","\n","      # extracting a small sample for re-training the model\n","      scaled_df_unknown_device_benign_sample, scaled_df_unknown_device_benign_remaining = np.split(scaled_df_unknown_device_benign.sample(frac=1), [int(0.10*length_unknown_device_benign)])\n","\n","      # splitting the small sample of data into train, opt and test datasets.\n","      scaled_df_unknown_device_benign_sample_train, scaled_df_unknown_device_benign_sample_opt, scaled_df_unknown_device_benign_sample_test = np.split(scaled_df_unknown_device_benign_sample, [int(3/5*len(scaled_df_unknown_device_benign_sample)), int(4/5*len(scaled_df_unknown_device_benign_sample))])\n","\n","      tl_results_file_writing('\\n\\nINFORMATION ON SAMPLED DATA')\n","      buffer = io.StringIO()\n","      scaled_df_unknown_device_benign_sample.info(buf=buffer)\n","      tl_buffer_results_file_writing()\n","\n","      tl_results_file_writing(\"\\nINFORMATION ON REMAINING BENIGN DATA\")\n","      buffer = io.StringIO()\n","      scaled_df_unknown_device_benign_remaining.info(buf=buffer)\n","      tl_buffer_results_file_writing()\n","\n","      tl_results_file_writing(\"\\nSAMPLE DATA SPLIT FOR TRAIN, OPT AND TEST\")\n","      buffer = io.StringIO()\n","      scaled_df_unknown_device_benign_sample_train.info(buf=buffer)\n","      tl_buffer_results_file_writing()\n","\n","      buffer = io.StringIO()\n","      scaled_df_unknown_device_benign_sample_opt.info(buf=buffer)\n","      tl_buffer_results_file_writing\n","\n","      buffer = io.StringIO()\n","      scaled_df_unknown_device_benign_sample_test.info(buf=buffer)\n","      tl_buffer_results_file_writing\n","\n","\n","      ## Skipping the Fisher score part\n","      #unknown_scored = fisher_score(scaled_df_unknown_device_benign_sample, scaled_df_unknown_device_attack, unknown_device, Unknown_F_Score_File)\n","      \n","      #print(unknown_scored)\n","\n","      ### Checking the Original Anomaly models performance against Unknown sampled data.\n","      tl_results_file_writing('\\n\\n Model Accuracy for Malware against unknown device')\n","      pre_tl_results = unknown_anomaly_detect_func(scaled_df_unknown_device_benign_sample, scaled_df_unknown_device_attack, unknown_device, original_model_best_threshold, model, scaler, fs, unknown_device_confusion_matrix_figure_original_model_threshold)\n","      pre_tl_base_acc = pre_tl_results[0]  \n","\n","\n","\n","      ##### TRANSFERING LEARNING ####\n","\n","\n","      tl_results_file_writing(\"\\n\\n CREATING A MODEL FOR TRANSFER LEARNING\")\n","      # making a copy of the original model\n","\n","      transfer_model = model\n","\n","      # Freezing all layers except the three inner most layers.\n","\n","      for layer in transfer_model.layers[0:3]:\n","        layer.trainable = False\n","\n","      for layer in transfer_model.layers[-3:]:\n","        layer.trainable = False\n","\n","      for layer in transfer_model.layers[:]:\n","        print(layer, layer.trainable)\n","\n","      ## Re-Initialization of layers in the center\n","      initializer = keras.initializers.GlorotUniform()\n","      #s = K.get_session()\n","      for layer in transfer_model.layers[3:6]:\n","        #layer.kernel.initializer.run(session=s)\n","        layer.set_weights([initializer(shape=w.shape) for w in layer.get_weights()])\n","\n","      tl_results_file_writing('\\n we need to be careful on using the same number of features on which the earlier model is built \\n')\n","\n","      tl_results_file_writing(str(len(fs)))\n","      tl_results_file_writing('\\n')\n","      tl_results_file_writing(str(transfer_model.layers[0].input_shape[0][1]))\n","      tl_results_file_writing('\\n')\n","\n","      # Here cap the max number of features to be used o be equal to the input layer of the previous model.\n","\n","      max_features = transfer_model.layers[0].input_shape[0][1]\n","      print(\"Max Features: \" + str(max_features))\n","      for top_n_features in [max_features]: # for loop runs only once. because there is a single item in the list only. The number\n","                                            # describes the number of top features that shall be selected \n","                                            # fs = [it['feature'] for it in scored[:top_n_features]] # fs is a list of feature names in order of decreasing\n","                                            # F-score\n","        print(\"Top N Features\" + str(top_n_features))\n","        unknown_fs = []\n","        for it in scores[:top_n_features]:\n","          #if it['score'] > use_features_with_fisher_score_greater_than:  \n","          unknown_fs.append(it['feature'])\n","\n","        features_to_be_used = len(unknown_fs)\n","        tl_results_file_writing(str(features_to_be_used))\n","        tl_results_file_writing('\\n')\n","\n","        DF_UNKNOWN_BENIGN_TRAIN = scaled_df_unknown_device_benign_sample_train[unknown_fs]\n","        DF_UNKNOWN_BENIGN_OPT = scaled_df_unknown_device_benign_sample_opt[unknown_fs]\n","        DF_UNKNOWN_BENIGN_TEST = scaled_df_unknown_device_benign_sample_test[unknown_fs]\n","    \n","        #checkpoint_filepath=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/Generic_Anomaly_Detection_Malware_TRANSFER-LEARNING-SimpleHomeCamera-{features_to_be_used}.h5\"\n","        transfer_cp = ModelCheckpoint(filepath=transfer_learning_checkpoint_filepath,\n","                                  monitor='val_loss',\n","                               save_best_only=True,\n","                               verbose=1)\n","    \n","        transfer_es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","        start = time.time()\n","        epochs = 100\n","        transfer_history = transfer_model.fit(DF_UNKNOWN_BENIGN_TRAIN, DF_UNKNOWN_BENIGN_TRAIN,\n","                    epochs=epochs,\n","                    validation_data=(DF_UNKNOWN_BENIGN_OPT, DF_UNKNOWN_BENIGN_OPT),\n","                    verbose=1,\n","                    callbacks=[transfer_cp, transfer_es])\n","    \n","        end = time.time()\n","        tl_results_file_writing('\\n\\n ----> Transfer Model Training Time Is: ')\n","        tl_results_file_writing(str(end - start))\n","        tl_results_file_writing('\\n\\n')\n","\n","        with open(tl_results_file_name, 'at') as f:\n","          with redirect_stdout(f):\n","            transfer_model.summary()\n","        f.close()\n","\n","        tl_original_model_path=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/transfer-model/model.h5\"\n","        transfer_model.save(tl_original_model_path)\n","\n","      ## till here, we have created a model using X number of top features \n","\n","\n","      #### Defining Anomaly Error Threshold for the Transferred Model\n","\n","      tl_results_file_writing('\\n\\n  <<  Transferred Model: Defining Anomaly Threshold  >>  \\n\\n')\n","    \n","      df_benign_unknown_device_test_predictions = transfer_model.predict(scaled_df_unknown_device_benign_sample_test[unknown_fs])\n","      unknown_difference = scaled_df_unknown_device_benign_sample_test[unknown_fs] - df_benign_unknown_device_test_predictions\n","    \n","      unknown_mse = np.mean(np.power(scaled_df_unknown_device_benign_sample_test[unknown_fs] - df_benign_unknown_device_test_predictions, 2), axis=1) # Mean-Squared-Error is calculated for each row,\n","      unknown_mean = unknown_mse.mean() # We calculate the mean of the whole series, that is the mean mse for all the benign test cases.\n","      unknown_std = unknown_mse.std() # And we calculate the standard deviation of the mse series, containing only the test cases.\n","\n","      unknown_mse = pd.Series(unknown_mse) #converting np array to dataframe series\n","\n","      tl_results_file_writing(str(\"MIN of MSE: \" + str(unknown_mse.min())) + \"\\n\")\n","      tl_results_file_writing(str(\"MAX of MSE: \" + str(unknown_mse.max())) + \"\\n\")\n","      tl_results_file_writing(str(\"MEAN of MSE: \" + str(unknown_mean)) + \"\\n\")\n","      tl_results_file_writing(str(\"STD of MSE:  \" + str(unknown_std)) + \"\\n\")\n","\n","      unknown_mse_min = unknown_mse.min()\n","      unknown_mse_max = unknown_mse.max()\n","      tl_results_file_writing(str(\"\\n Max Threshold = MSE_MAX: \" + str(unknown_mse_max))  + \"\\n\")\n","\n","      unknown_max_std_multiplier = int((unknown_mse_max - unknown_mean) / unknown_std)\n","      tl_results_file_writing(str(\"\\n MAX_STD_Multiplier = \" + str(unknown_max_std_multiplier)) + \"\\n\")\n","\n","      transfer_model_error_distribution=f\"/content/drive/My Drive/thesis-unsub/unsub/anomaly-transferlearning/looped_run_without_fs/{malware}/{known_device}/{unknown_device}/transfer-model/error-distribution.png\"\n","      unknown_mse_plot = unknown_mse.plot.hist(bins=20, color='#0033cc')\n","      unknown_mse_plot.set_facecolor('#ffffff')\n","      unknown_mse_plot.set_xlim((unknown_mse_min, unknown_mse_max))\n","      unknown_mse_plot.set_ylim((0, unknown_mse[unknown_mse <= unknown_mse_max].count()))\n","      fig = unknown_mse_plot.get_figure()\n","      fig.savefig(transfer_model_error_distribution)\n","\n","\n","      ### Getting a base accuracy of the model using MSE-MAX threshold.\n","      post_tl_results = unknown_anomaly_detect_func(scaled_df_unknown_device_benign_sample_test, scaled_df_unknown_device_attack, unknown_device, unknown_mse_max, transfer_model, scaler, unknown_fs, unknown_device_confusion_matrix_figure_transfer_model_threshold)\n","      post_tl_base_acc = post_tl_results[0]    \n","      post_tl_anomaly_detect_01_X_test = post_tl_results[1]\n","      post_tl_anomaly_detect_01_Y_test  = post_tl_results[2]\n","\n","\n","      ### Finding the threshold with best scores\n","\n","      tl_results_file_writing('\\n\\n <<--=== Finding Best Performning Threshold After Transfer Learning ===-->> \\n')\n","\n","      unknown_quantile_mse=unknown_mse\n","\n","      transfer_model_best_results = tl_best_results_finder(post_tl_base_acc, unknown_mse, unknown_quantile_mse, transfer_model, scaler, malware, unknown_device, post_tl_anomaly_detect_01_X_test, post_tl_anomaly_detect_01_Y_test, unknown_device_confusion_matrix_figure_transfer_model_best_percentile)\n","      transfer_model_best_threshold = transfer_model_best_results[0]\n","      transfer_model_best_percentile = transfer_model_best_results[1]\n","\n","\n","      #### FINALLY, finding the performance of the Transfer Learning model on the unknown data\n","\n","      final_performance_results = unknown_anomaly_detect_func(scaled_df_unknown_device_benign_remaining, scaled_df_unknown_device_attack, unknown_device, transfer_model_best_threshold, transfer_model, scaler, unknown_fs, unknown_device_confusion_matrix_figure_transfer_model_final_performance)\n","      tl_model_best_accuracy = final_performance_results[0]\n","      tl_model_best_precision = final_performance_results[3]\n","      tl_model_best_recall = final_performance_results[4]\n","      tl_model_best_f1score = final_performance_results[5]\n","\n","      results_file_writing(str(unknown_device))\n","      results_file_writing('\\n')\n","      results_file_writing(str('ACCURACY: ' + str(tl_model_best_accuracy)))\n","      results_file_writing('\\n')\n","      results_file_writing(str('PRECISION: ' + str(tl_model_best_precision)))\n","      results_file_writing('\\n')\n","      results_file_writing(str('RECALL: ' + str(tl_model_best_recall)))\n","      results_file_writing('\\n')\n","      results_file_writing(str('F1-SCORE: ' + str(tl_model_best_f1score)))\n","      results_file_writing('\\n ------- \\n')      \n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_5mItKrgx5o4","outputId":"31ada27a-8728-4b9d-f3d7-719b8865fdbe","executionInfo":{"status":"ok","timestamp":1643545668663,"user_tz":-300,"elapsed":17711377,"user":{"displayName":"Unsub Shafiq","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07945986632191365791"}}},"execution_count":null,"outputs":[]}]}